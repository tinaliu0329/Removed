{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ad8156",
   "metadata": {},
   "source": [
    "## Auxiliary Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551f914",
   "metadata": {},
   "source": [
    "#### In this notebook, I repeat the parsing steps as the Main Code has demonstrated using spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858a7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import spaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82f8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the remaining texts\n",
    "StoneB = open(\"The story of the stone(21-40).txt\").read()\n",
    "StoneC = open(\"The story of the stone(41-60).txt\").read()\n",
    "StoneD = open(\"The story of the stone(61-80).txt\").read()\n",
    "StoneE = open(\"The story of the stone(81-100).txt\").read()\n",
    "StoneF = open(\"The story of the stone(101-120).txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d422463a",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8332d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the module for punctuation removal\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b17f83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove punctuation for StoneB\n",
    "for char in punctuation:\n",
    "    StoneB = StoneB.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68ae2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove punctuation for StoneC\n",
    "for char in punctuation:\n",
    "    StoneC = StoneC.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "915fdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove punctuation for StoneD\n",
    "for char in punctuation:\n",
    "    StoneD = StoneD.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42fd41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove punctuation for StoneE\n",
    "for char in punctuation:\n",
    "    StoneE = StoneE.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a08f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove punctuation for StoneF\n",
    "for char in punctuation:\n",
    "    StoneF = StoneF.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cde6b",
   "metadata": {},
   "source": [
    "Information on the length of each file is measured and recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed630ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142366\n"
     ]
    }
   ],
   "source": [
    "## How many words in StoneB?\n",
    "print(len(StoneB.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a5a8753",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157076\n"
     ]
    }
   ],
   "source": [
    "## How many words in StoneC?\n",
    "print(len(StoneC.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98e8133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164560\n"
     ]
    }
   ],
   "source": [
    "## How many words in StoneD?\n",
    "print(len(StoneD.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "141a55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122370\n"
     ]
    }
   ],
   "source": [
    "## How many words in StoneE?\n",
    "print(len(StoneE.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fe08e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129675\n"
     ]
    }
   ],
   "source": [
    "## How many words in StoneF?\n",
    "print(len(StoneF.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8679bfa",
   "metadata": {},
   "source": [
    "### Parse Using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081da6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "from __future__ import unicode_literals\n",
    "import spacy,en_core_web_sm\n",
    "from collections import Counter\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6c422",
   "metadata": {},
   "source": [
    "#### StoneB: Parsing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af0d8d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN 11.49%\n",
      "NUM 0.62%\n",
      "SPACE 12.99%\n",
      "PROPN 5.71%\n",
      "VERB 13.94%\n",
      "ADV 5.59%\n",
      "PART 3.19%\n",
      "PRON 11.52%\n",
      "ADP 9.05%\n",
      "CCONJ 2.88%\n",
      "ADJ 4.44%\n",
      "AUX 4.87%\n",
      "SCONJ 1.44%\n",
      "PUNCT 4.61%\n",
      "DET 7.37%\n",
      "INTJ 0.24%\n",
      "X 0.04%\n",
      "SYM 0.00%\n"
     ]
    }
   ],
   "source": [
    "c = Counter(([token.pos_ for token in nlp(StoneB)]))\n",
    "sbase = sum(c.values())\n",
    "for el, cnt in c.items():\n",
    "    print(el, '{0:2.2f}%'.format((100.0* cnt)/sbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ff0d6",
   "metadata": {},
   "source": [
    "#### StoneC: Parsing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b9b3aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN 11.75%\n",
      "NUM 0.74%\n",
      "SPACE 12.98%\n",
      "PROPN 5.42%\n",
      "VERB 13.81%\n",
      "DET 7.57%\n",
      "ADJ 4.52%\n",
      "ADP 9.39%\n",
      "CCONJ 2.90%\n",
      "PUNCT 3.71%\n",
      "AUX 4.99%\n",
      "X 0.03%\n",
      "PRON 11.31%\n",
      "PART 3.29%\n",
      "ADV 5.74%\n",
      "SCONJ 1.64%\n",
      "INTJ 0.20%\n",
      "SYM 0.00%\n"
     ]
    }
   ],
   "source": [
    "c = Counter(([token.pos_ for token in nlp(StoneC)]))\n",
    "sbase = sum(c.values())\n",
    "for el, cnt in c.items():\n",
    "    print(el, '{0:2.2f}%'.format((100.0* cnt)/sbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e702b",
   "metadata": {},
   "source": [
    "#### StoneD: Parsing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f373b8d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN 12.32%\n",
      "NUM 0.75%\n",
      "SPACE 6.88%\n",
      "PROPN 5.21%\n",
      "VERB 14.96%\n",
      "ADP 10.24%\n",
      "DET 8.20%\n",
      "PRON 12.43%\n",
      "AUX 5.47%\n",
      "PART 3.80%\n",
      "CCONJ 3.12%\n",
      "ADV 6.15%\n",
      "ADJ 4.75%\n",
      "PUNCT 3.73%\n",
      "SCONJ 1.77%\n",
      "INTJ 0.21%\n",
      "X 0.00%\n",
      "SYM 0.00%\n"
     ]
    }
   ],
   "source": [
    "c = Counter(([token.pos_ for token in nlp(StoneD)]))\n",
    "sbase = sum(c.values())\n",
    "for el, cnt in c.items():\n",
    "    print(el, '{0:2.2f}%'.format((100.0* cnt)/sbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e442c",
   "metadata": {},
   "source": [
    "#### StoneE: Parsing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2aada769",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACE 7.20%\n",
      "NOUN 12.23%\n",
      "NUM 0.59%\n",
      "ADJ 4.80%\n",
      "VERB 14.98%\n",
      "CCONJ 3.47%\n",
      "DET 8.07%\n",
      "PROPN 7.20%\n",
      "ADV 5.98%\n",
      "AUX 5.09%\n",
      "ADP 9.67%\n",
      "PART 3.55%\n",
      "PRON 11.50%\n",
      "SCONJ 1.30%\n",
      "PUNCT 4.08%\n",
      "INTJ 0.28%\n",
      "X 0.01%\n"
     ]
    }
   ],
   "source": [
    "c = Counter(([token.pos_ for token in nlp(StoneE)]))\n",
    "sbase = sum(c.values())\n",
    "for el, cnt in c.items():\n",
    "    print(el, '{0:2.2f}%'.format((100.0* cnt)/sbase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285459c",
   "metadata": {},
   "source": [
    "#### StoneF: Parsing Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "547a89fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPACE 6.98%\n",
      "NOUN 12.59%\n",
      "NUM 0.56%\n",
      "ADP 9.57%\n",
      "PROPN 6.84%\n",
      "DET 7.98%\n",
      "ADJ 4.97%\n",
      "VERB 14.74%\n",
      "CCONJ 3.78%\n",
      "PRON 11.59%\n",
      "SCONJ 1.41%\n",
      "AUX 5.38%\n",
      "PART 3.53%\n",
      "ADV 6.17%\n",
      "PUNCT 3.70%\n",
      "INTJ 0.20%\n",
      "SYM 0.00%\n"
     ]
    }
   ],
   "source": [
    "c = Counter(([token.pos_ for token in nlp(StoneF)]))\n",
    "sbase = sum(c.values())\n",
    "for el, cnt in c.items():\n",
    "    print(el, '{0:2.2f}%'.format((100.0* cnt)/sbase))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
